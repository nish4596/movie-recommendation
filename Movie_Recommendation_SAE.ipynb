{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOENCODERS\n",
    "Real data around us like images and documentations are of very high dimensions. Autoencoders can learn a simple representation of it. They are a class of unsupervised neural networks. The architecture consists of an encoder, a bottleneck and a decoder. The output is the reconstruction of the input and so the dimensions of input and output are equal. The objective here is to reduce the reconstruction loss by learning the weights through techiniques like backpropagation. <br><br>\n",
    "\n",
    "It is similar to PCA but with a nonlinear activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT\n",
    "In this project, a movie recommendation system model is designed using Stacked Autoenoders which is a type of autoencoders that has more than one hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn #for neural networks\n",
    "import torch.nn.parallel  #for parallel computation\n",
    "import torch.optim as optim #for optimizers\n",
    "import torch.utils.data #for tools\n",
    "from torch.autograd import Variable #for Stocahstic Grad desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(r'C:\\Users\\pnish\\OneDrive\\Documents\\Projects\\Recommendation System - Autoencoder\\AutoEncoders\\ml-1m\\ml-1m\\movies.dat', sep='::',header=None,engine='python',encoding='latin-1')\n",
    "users = pd.read_csv(r'C:\\Users\\pnish\\OneDrive\\Documents\\Projects\\Recommendation System - Autoencoder\\AutoEncoders\\ml-1m\\ml-1m\\users.dat', sep='::',header=None,engine='python',encoding='latin-1')\n",
    "ratings = pd.read_csv(r'C:\\Users\\pnish\\OneDrive\\Documents\\Projects\\Recommendation System - Autoencoder\\AutoEncoders\\ml-1m\\ml-1m\\ratings.dat', sep='::',header=None,engine='python',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies data\n",
    "The movies data consists of three columns: Movie ID, Movie name and the genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3883, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users data\n",
    "The users data consists of four column: User ID, Gender, Age, Job code and visit code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(users.shape)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings data\n",
    "The ratings data consists of four columns: User ID, Movie ID, Ratings and Time stamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training and test sets\n",
    "The data used for building the model is similar to the ratings datasets. It consists of 100,000 records and split randomly into training set and test. 80% of the data is used as training set to train the model and the remaning is used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add header=None\n",
    "training_set = pd.read_csv(r'C:\\Users\\pnish\\OneDrive\\Documents\\Projects\\Recommendation System - Autoencoder\\AutoEncoders\\ml-100k\\ml-100k\\u1.base',delimiter='\\t')\n",
    "training_set = np.array(training_set,dtype='int') #Converting into an array since pytorch works only on arrays\n",
    "test_set = pd.read_csv(r'C:\\Users\\pnish\\OneDrive\\Documents\\Projects\\Recommendation System - Autoencoder\\AutoEncoders\\ml-100k\\ml-100k\\u1.test',delimiter='\\t')\n",
    "test_set = np.array(test_set,dtype='int') #Converting into an array since pytorch works only on arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the number of users and movies\n",
    "The total number of movies and users are needed because the training and test data needed to be converted into a matrix that has users as the lines, movies as the column and the corresponding rating in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "print(nb_users,nb_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1,nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0]==id_users]\n",
    "        id_ratings = data[:,2][data[:,0]==id_users]\n",
    "        ratings= np.zeros(nb_movies)\n",
    "        ratings[id_movies-1]=id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=convert(training_set)\n",
    "testing_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into Torch Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the architecture of the Neural Network\n",
    "This model has three hidden layers between the input and output layers. The number of nodes in the three hidden layers are 20, 10 and 20. The input layer consists of number of nodes equal to the number of columns in the data (i.e., the number of movies). The autoencoder tries to recreate the input as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(SAE,self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies,20)\n",
    "        self.fc2 = nn.Linear(20,10)\n",
    "        self.fc3 = nn.Linear(10,20)\n",
    "        self.fc4 = nn.Linear(20,nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay =0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnish\\.conda\\envs\\tf\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Loss:  tensor(1.7717)\n",
      "Epoch:  2  Loss:  tensor(1.0968)\n",
      "Epoch:  3  Loss:  tensor(1.0534)\n",
      "Epoch:  4  Loss:  tensor(1.0386)\n",
      "Epoch:  5  Loss:  tensor(1.0308)\n",
      "Epoch:  6  Loss:  tensor(1.0269)\n",
      "Epoch:  7  Loss:  tensor(1.0239)\n",
      "Epoch:  8  Loss:  tensor(1.0219)\n",
      "Epoch:  9  Loss:  tensor(1.0207)\n",
      "Epoch:  10  Loss:  tensor(1.0198)\n",
      "Epoch:  11  Loss:  tensor(1.0189)\n",
      "Epoch:  12  Loss:  tensor(1.0185)\n",
      "Epoch:  13  Loss:  tensor(1.0179)\n",
      "Epoch:  14  Loss:  tensor(1.0177)\n",
      "Epoch:  15  Loss:  tensor(1.0173)\n",
      "Epoch:  16  Loss:  tensor(1.0169)\n",
      "Epoch:  17  Loss:  tensor(1.0170)\n",
      "Epoch:  18  Loss:  tensor(1.0166)\n",
      "Epoch:  19  Loss:  tensor(1.0165)\n",
      "Epoch:  20  Loss:  tensor(1.0163)\n",
      "Epoch:  21  Loss:  tensor(1.0161)\n",
      "Epoch:  22  Loss:  tensor(1.0160)\n",
      "Epoch:  23  Loss:  tensor(1.0158)\n",
      "Epoch:  24  Loss:  tensor(1.0156)\n",
      "Epoch:  25  Loss:  tensor(1.0158)\n",
      "Epoch:  26  Loss:  tensor(1.0156)\n",
      "Epoch:  27  Loss:  tensor(1.0156)\n",
      "Epoch:  28  Loss:  tensor(1.0151)\n",
      "Epoch:  29  Loss:  tensor(1.0128)\n",
      "Epoch:  30  Loss:  tensor(1.0120)\n",
      "Epoch:  31  Loss:  tensor(1.0095)\n",
      "Epoch:  32  Loss:  tensor(1.0098)\n",
      "Epoch:  33  Loss:  tensor(1.0057)\n",
      "Epoch:  34  Loss:  tensor(1.0054)\n",
      "Epoch:  35  Loss:  tensor(1.0015)\n",
      "Epoch:  36  Loss:  tensor(1.0005)\n",
      "Epoch:  37  Loss:  tensor(0.9971)\n",
      "Epoch:  38  Loss:  tensor(0.9944)\n",
      "Epoch:  39  Loss:  tensor(0.9958)\n",
      "Epoch:  40  Loss:  tensor(0.9946)\n",
      "Epoch:  41  Loss:  tensor(0.9916)\n",
      "Epoch:  42  Loss:  tensor(0.9912)\n",
      "Epoch:  43  Loss:  tensor(0.9890)\n",
      "Epoch:  44  Loss:  tensor(0.9902)\n",
      "Epoch:  45  Loss:  tensor(0.9869)\n",
      "Epoch:  46  Loss:  tensor(0.9870)\n",
      "Epoch:  47  Loss:  tensor(0.9826)\n",
      "Epoch:  48  Loss:  tensor(0.9810)\n",
      "Epoch:  49  Loss:  tensor(0.9777)\n",
      "Epoch:  50  Loss:  tensor(0.9844)\n",
      "Epoch:  51  Loss:  tensor(0.9805)\n",
      "Epoch:  52  Loss:  tensor(0.9793)\n",
      "Epoch:  53  Loss:  tensor(0.9744)\n",
      "Epoch:  54  Loss:  tensor(0.9792)\n",
      "Epoch:  55  Loss:  tensor(0.9784)\n",
      "Epoch:  56  Loss:  tensor(0.9761)\n",
      "Epoch:  57  Loss:  tensor(0.9710)\n",
      "Epoch:  58  Loss:  tensor(0.9680)\n",
      "Epoch:  59  Loss:  tensor(0.9665)\n",
      "Epoch:  60  Loss:  tensor(0.9673)\n",
      "Epoch:  61  Loss:  tensor(0.9651)\n",
      "Epoch:  62  Loss:  tensor(0.9633)\n",
      "Epoch:  63  Loss:  tensor(0.9617)\n",
      "Epoch:  64  Loss:  tensor(0.9602)\n",
      "Epoch:  65  Loss:  tensor(0.9564)\n",
      "Epoch:  66  Loss:  tensor(0.9580)\n",
      "Epoch:  67  Loss:  tensor(0.9547)\n",
      "Epoch:  68  Loss:  tensor(0.9563)\n",
      "Epoch:  69  Loss:  tensor(0.9524)\n",
      "Epoch:  70  Loss:  tensor(0.9528)\n",
      "Epoch:  71  Loss:  tensor(0.9491)\n",
      "Epoch:  72  Loss:  tensor(0.9511)\n",
      "Epoch:  73  Loss:  tensor(0.9531)\n",
      "Epoch:  74  Loss:  tensor(0.9498)\n",
      "Epoch:  75  Loss:  tensor(0.9462)\n",
      "Epoch:  76  Loss:  tensor(0.9478)\n",
      "Epoch:  77  Loss:  tensor(0.9452)\n",
      "Epoch:  78  Loss:  tensor(0.9460)\n",
      "Epoch:  79  Loss:  tensor(0.9431)\n",
      "Epoch:  80  Loss:  tensor(0.9449)\n",
      "Epoch:  81  Loss:  tensor(0.9422)\n",
      "Epoch:  82  Loss:  tensor(0.9424)\n",
      "Epoch:  83  Loss:  tensor(0.9406)\n",
      "Epoch:  84  Loss:  tensor(0.9417)\n",
      "Epoch:  85  Loss:  tensor(0.9397)\n",
      "Epoch:  86  Loss:  tensor(0.9408)\n",
      "Epoch:  87  Loss:  tensor(0.9387)\n",
      "Epoch:  88  Loss:  tensor(0.9397)\n",
      "Epoch:  89  Loss:  tensor(0.9377)\n",
      "Epoch:  90  Loss:  tensor(0.9385)\n",
      "Epoch:  91  Loss:  tensor(0.9364)\n",
      "Epoch:  92  Loss:  tensor(0.9375)\n",
      "Epoch:  93  Loss:  tensor(0.9356)\n",
      "Epoch:  94  Loss:  tensor(0.9364)\n",
      "Epoch:  95  Loss:  tensor(0.9346)\n",
      "Epoch:  96  Loss:  tensor(0.9356)\n",
      "Epoch:  97  Loss:  tensor(0.9338)\n",
      "Epoch:  98  Loss:  tensor(0.9348)\n",
      "Epoch:  99  Loss:  tensor(0.9333)\n",
      "Epoch:  100  Loss:  tensor(0.9338)\n",
      "Epoch:  101  Loss:  tensor(0.9325)\n",
      "Epoch:  102  Loss:  tensor(0.9329)\n",
      "Epoch:  103  Loss:  tensor(0.9316)\n",
      "Epoch:  104  Loss:  tensor(0.9322)\n",
      "Epoch:  105  Loss:  tensor(0.9311)\n",
      "Epoch:  106  Loss:  tensor(0.9317)\n",
      "Epoch:  107  Loss:  tensor(0.9303)\n",
      "Epoch:  108  Loss:  tensor(0.9312)\n",
      "Epoch:  109  Loss:  tensor(0.9298)\n",
      "Epoch:  110  Loss:  tensor(0.9304)\n",
      "Epoch:  111  Loss:  tensor(0.9293)\n",
      "Epoch:  112  Loss:  tensor(0.9297)\n",
      "Epoch:  113  Loss:  tensor(0.9285)\n",
      "Epoch:  114  Loss:  tensor(0.9292)\n",
      "Epoch:  115  Loss:  tensor(0.9278)\n",
      "Epoch:  116  Loss:  tensor(0.9285)\n",
      "Epoch:  117  Loss:  tensor(0.9274)\n",
      "Epoch:  118  Loss:  tensor(0.9280)\n",
      "Epoch:  119  Loss:  tensor(0.9268)\n",
      "Epoch:  120  Loss:  tensor(0.9273)\n",
      "Epoch:  121  Loss:  tensor(0.9263)\n",
      "Epoch:  122  Loss:  tensor(0.9266)\n",
      "Epoch:  123  Loss:  tensor(0.9257)\n",
      "Epoch:  124  Loss:  tensor(0.9259)\n",
      "Epoch:  125  Loss:  tensor(0.9248)\n",
      "Epoch:  126  Loss:  tensor(0.9254)\n",
      "Epoch:  127  Loss:  tensor(0.9241)\n",
      "Epoch:  128  Loss:  tensor(0.9247)\n",
      "Epoch:  129  Loss:  tensor(0.9237)\n",
      "Epoch:  130  Loss:  tensor(0.9240)\n",
      "Epoch:  131  Loss:  tensor(0.9232)\n",
      "Epoch:  132  Loss:  tensor(0.9235)\n",
      "Epoch:  133  Loss:  tensor(0.9227)\n",
      "Epoch:  134  Loss:  tensor(0.9230)\n",
      "Epoch:  135  Loss:  tensor(0.9220)\n",
      "Epoch:  136  Loss:  tensor(0.9224)\n",
      "Epoch:  137  Loss:  tensor(0.9216)\n",
      "Epoch:  138  Loss:  tensor(0.9218)\n",
      "Epoch:  139  Loss:  tensor(0.9213)\n",
      "Epoch:  140  Loss:  tensor(0.9216)\n",
      "Epoch:  141  Loss:  tensor(0.9208)\n",
      "Epoch:  142  Loss:  tensor(0.9209)\n",
      "Epoch:  143  Loss:  tensor(0.9201)\n",
      "Epoch:  144  Loss:  tensor(0.9204)\n",
      "Epoch:  145  Loss:  tensor(0.9199)\n",
      "Epoch:  146  Loss:  tensor(0.9200)\n",
      "Epoch:  147  Loss:  tensor(0.9195)\n",
      "Epoch:  148  Loss:  tensor(0.9195)\n",
      "Epoch:  149  Loss:  tensor(0.9192)\n",
      "Epoch:  150  Loss:  tensor(0.9191)\n",
      "Epoch:  151  Loss:  tensor(0.9187)\n",
      "Epoch:  152  Loss:  tensor(0.9186)\n",
      "Epoch:  153  Loss:  tensor(0.9184)\n",
      "Epoch:  154  Loss:  tensor(0.9182)\n",
      "Epoch:  155  Loss:  tensor(0.9179)\n",
      "Epoch:  156  Loss:  tensor(0.9179)\n",
      "Epoch:  157  Loss:  tensor(0.9179)\n",
      "Epoch:  158  Loss:  tensor(0.9177)\n",
      "Epoch:  159  Loss:  tensor(0.9172)\n",
      "Epoch:  160  Loss:  tensor(0.9172)\n",
      "Epoch:  161  Loss:  tensor(0.9170)\n",
      "Epoch:  162  Loss:  tensor(0.9169)\n",
      "Epoch:  163  Loss:  tensor(0.9167)\n",
      "Epoch:  164  Loss:  tensor(0.9166)\n",
      "Epoch:  165  Loss:  tensor(0.9164)\n",
      "Epoch:  166  Loss:  tensor(0.9164)\n",
      "Epoch:  167  Loss:  tensor(0.9161)\n",
      "Epoch:  168  Loss:  tensor(0.9159)\n",
      "Epoch:  169  Loss:  tensor(0.9158)\n",
      "Epoch:  170  Loss:  tensor(0.9159)\n",
      "Epoch:  171  Loss:  tensor(0.9156)\n",
      "Epoch:  172  Loss:  tensor(0.9155)\n",
      "Epoch:  173  Loss:  tensor(0.9153)\n",
      "Epoch:  174  Loss:  tensor(0.9152)\n",
      "Epoch:  175  Loss:  tensor(0.9149)\n",
      "Epoch:  176  Loss:  tensor(0.9150)\n",
      "Epoch:  177  Loss:  tensor(0.9147)\n",
      "Epoch:  178  Loss:  tensor(0.9147)\n",
      "Epoch:  179  Loss:  tensor(0.9144)\n",
      "Epoch:  180  Loss:  tensor(0.9144)\n",
      "Epoch:  181  Loss:  tensor(0.9140)\n",
      "Epoch:  182  Loss:  tensor(0.9141)\n",
      "Epoch:  183  Loss:  tensor(0.9139)\n",
      "Epoch:  184  Loss:  tensor(0.9138)\n",
      "Epoch:  185  Loss:  tensor(0.9136)\n",
      "Epoch:  186  Loss:  tensor(0.9135)\n",
      "Epoch:  187  Loss:  tensor(0.9132)\n",
      "Epoch:  188  Loss:  tensor(0.9131)\n",
      "Epoch:  189  Loss:  tensor(0.9131)\n",
      "Epoch:  190  Loss:  tensor(0.9131)\n",
      "Epoch:  191  Loss:  tensor(0.9129)\n",
      "Epoch:  192  Loss:  tensor(0.9127)\n",
      "Epoch:  193  Loss:  tensor(0.9127)\n",
      "Epoch:  194  Loss:  tensor(0.9126)\n",
      "Epoch:  195  Loss:  tensor(0.9124)\n",
      "Epoch:  196  Loss:  tensor(0.9122)\n",
      "Epoch:  197  Loss:  tensor(0.9120)\n",
      "Epoch:  198  Loss:  tensor(0.9118)\n",
      "Epoch:  199  Loss:  tensor(0.9117)\n",
      "Epoch:  200  Loss:  tensor(0.9117)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0 # initial training loss\n",
    "    s = 0. # number of users who rated at least one movie\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) # training_set[id_user] is a single vector and pytorch wont accept this. There need to be a batch of vectors (size[1,1682])\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data>0)>0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False # to make sure that we dont compute the gradient descent to the target\n",
    "            output[target==0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward() #to find the direction to which the weight should be updated\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step() #finds the intensity of weight update\n",
    "    print('Epoch: ',epoch,' Loss: ',train_loss/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the class object becomes our model. Now we can use this model to predict the test data. The parameters of the model can be accessed using the method state_dict() (Eg. : sae.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are parameters of our trained model: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-2.8530e-02, -3.8972e-03,  7.4315e-02,  ..., -9.4598e-04,\n",
       "                       -7.2531e-02, -1.0948e-02],\n",
       "                      [-8.3199e-02,  2.9801e-01, -3.1988e-02,  ..., -3.6588e-04,\n",
       "                       -3.9030e-03, -1.4574e-02],\n",
       "                      [ 1.3208e-01, -4.5119e-02,  8.4846e-02,  ..., -5.0668e-03,\n",
       "                       -2.2829e-02, -3.2755e-02],\n",
       "                      ...,\n",
       "                      [ 2.4811e-01,  1.7087e-02,  2.3530e-01,  ..., -2.4886e-02,\n",
       "                       -4.6826e-02, -3.0817e-02],\n",
       "                      [-4.8230e-02,  3.6995e-01, -1.8778e-01,  ..., -5.8407e-03,\n",
       "                       -2.6334e-02, -8.8783e-03],\n",
       "                      [-3.2568e-01, -1.7400e-02,  6.9348e-02,  ..., -7.0913e-03,\n",
       "                       -3.2973e-02,  1.7039e-03]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0997, -0.5760, -0.0306, -0.7905, -0.7104, -0.4718, -0.1169, -0.2361,\n",
       "                      -0.4689, -1.0015, -0.6133, -0.8056, -0.3197, -0.3248, -0.3713, -0.2459,\n",
       "                      -0.7513, -0.7180, -0.6415, -0.4220])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-6.2607e-01,  6.6328e-01, -9.2704e-01,  1.0416e+00,  4.9075e-01,\n",
       "                        5.4537e-01, -5.8080e-01,  5.5578e-01,  1.1931e-01,  5.7639e-01,\n",
       "                        7.5672e-01,  6.3397e-01, -3.9695e-01, -2.4716e-01,  6.1661e-01,\n",
       "                        8.4955e-02,  5.4890e-01,  9.6368e-01,  9.2275e-01,  7.6994e-01],\n",
       "                      [-6.2056e-01,  6.6573e-01, -9.1981e-01,  1.0693e+00,  4.9119e-01,\n",
       "                        5.5167e-01, -5.7160e-01,  5.7259e-01,  1.1871e-01,  5.8865e-01,\n",
       "                        7.7418e-01,  6.3607e-01, -3.8664e-01, -2.3953e-01,  6.1896e-01,\n",
       "                        8.4893e-02,  5.5339e-01,  9.9281e-01,  9.2838e-01,  7.7379e-01],\n",
       "                      [-5.4088e-01,  6.9160e-01, -7.6553e-01,  1.1171e+00,  8.9584e-01,\n",
       "                        8.6301e-01, -4.6575e-01,  8.0491e-01,  7.4950e-01,  1.2555e+00,\n",
       "                        8.1312e-01,  8.6337e-01, -5.8565e-01, -5.5523e-02,  5.4203e-01,\n",
       "                        3.0753e-02,  6.6249e-01,  1.5134e+00,  1.7290e+00,  7.0816e-01],\n",
       "                      [-4.7275e-01,  5.7129e-01, -8.7428e-01,  7.2890e-01,  1.1858e+00,\n",
       "                        1.0367e+00, -5.6130e-01, -1.5323e-01,  9.7896e-01,  1.5546e+00,\n",
       "                        9.8989e-01,  1.7202e+00, -3.8797e-01, -1.2215e-01,  4.7145e-01,\n",
       "                        1.7087e-03,  5.1600e-01,  5.9426e-01,  9.7101e-01,  6.3251e-01],\n",
       "                      [-5.6305e-01,  6.6849e-01, -7.6703e-01,  1.1943e+00,  6.8437e-01,\n",
       "                        7.3568e-01, -4.4708e-01,  8.3127e-01,  4.9106e-01,  9.6002e-01,\n",
       "                        5.9925e-01,  7.4313e-01, -4.7047e-01, -8.4329e-02,  5.7362e-01,\n",
       "                        5.9490e-02,  6.3395e-01,  1.3510e+00,  1.4858e+00,  7.3094e-01],\n",
       "                      [-5.2490e-01,  7.6416e-01, -6.8446e-01,  6.9928e-01,  1.0862e+00,\n",
       "                        8.3459e-01, -3.5495e-01, -2.2889e-02,  1.0459e+00,  1.4571e+00,\n",
       "                        9.6919e-01,  1.9163e+00, -5.8741e-01,  3.6846e-02,  4.5880e-01,\n",
       "                        1.2692e-02,  5.6734e-01,  5.7670e-01,  7.8339e-01,  6.2115e-01],\n",
       "                      [-6.2428e-01,  6.6414e-01, -9.2448e-01,  1.0519e+00,  4.8964e-01,\n",
       "                        5.4630e-01, -5.7766e-01,  5.6300e-01,  1.1780e-01,  5.7936e-01,\n",
       "                        7.6491e-01,  6.3337e-01, -3.9358e-01, -2.4486e-01,  6.1759e-01,\n",
       "                        8.5183e-02,  5.5053e-01,  9.7429e-01,  9.2255e-01,  7.7132e-01],\n",
       "                      [-4.7588e-01,  9.4584e-01, -3.2634e-01,  7.1887e-01,  9.6214e-01,\n",
       "                        6.7500e-01,  3.3898e-02,  3.7323e-01,  1.1736e+00,  1.2994e+00,\n",
       "                        9.8250e-01,  2.3614e+00, -8.3219e-01,  4.3062e-01,  4.5504e-01,\n",
       "                        3.8526e-02,  6.2399e-01,  7.9261e-01,  6.8300e-01,  6.1507e-01],\n",
       "                      [-5.0802e-01,  8.8698e-01, -4.9441e-01,  7.0850e-01,  1.0152e+00,\n",
       "                        7.1917e-01, -1.5132e-01,  1.8926e-01,  1.0796e+00,  1.3485e+00,\n",
       "                        9.7403e-01,  2.0847e+00, -7.4159e-01,  2.3028e-01,  4.5509e-01,\n",
       "                        2.6176e-02,  6.0358e-01,  6.7305e-01,  7.1735e-01,  6.1660e-01],\n",
       "                      [-5.8785e-01,  6.6301e-01, -8.7284e-01,  1.1070e+00,  5.4687e-01,\n",
       "                        6.1599e-01, -5.3308e-01,  6.0225e-01,  2.2690e-01,  6.9543e-01,\n",
       "                        6.7569e-01,  6.9148e-01, -3.5995e-01, -1.9073e-01,  6.0438e-01,\n",
       "                        7.7351e-02,  5.6540e-01,  1.0432e+00,  1.0929e+00,  7.5877e-01]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-2.9074, -2.9047, -2.8005, -2.8954, -2.7751, -2.6938, -2.9055, -2.3089,\n",
       "                      -2.4846, -2.8668])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.1613,  0.1568,  0.4835,  0.6425,  0.2258,  0.5371,  0.1594,  0.3505,\n",
       "                        0.4328,  0.1296],\n",
       "                      [ 0.9552,  0.9775,  0.9478,  0.0074,  1.0535, -0.1732,  0.9637, -0.2426,\n",
       "                       -0.2243,  0.9901],\n",
       "                      [ 0.0890,  0.0829,  0.3141,  0.7467,  0.0880,  0.7474,  0.0866,  0.6546,\n",
       "                        0.6989,  0.0523],\n",
       "                      [ 0.3607,  0.3611,  0.4735,  0.9094,  0.3998,  1.1269,  0.3604,  1.4816,\n",
       "                        1.2970,  0.3690],\n",
       "                      [ 0.2720,  0.2711,  0.3741,  0.7770,  0.2839,  0.9376,  0.2707,  1.1902,\n",
       "                        1.0567,  0.2670],\n",
       "                      [ 0.1995,  0.1973,  0.5288,  0.6214,  0.2797,  0.5062,  0.1990,  0.3203,\n",
       "                        0.4022,  0.1734],\n",
       "                      [ 0.7459,  0.7598,  0.7580,  0.0710,  0.7989, -0.0875,  0.7509, -0.1607,\n",
       "                       -0.1420,  0.7547],\n",
       "                      [ 0.3201,  0.3203,  0.4227,  0.8407,  0.3470,  1.0387,  0.3194,  1.3646,\n",
       "                        1.1935,  0.3228],\n",
       "                      [ 0.6825,  0.6955,  0.7085,  0.0948,  0.7221, -0.0587,  0.6880, -0.1350,\n",
       "                       -0.1136,  0.6837],\n",
       "                      [ 1.0141,  1.0388,  1.0243,  0.0063,  1.1401, -0.1835,  1.0235, -0.2578,\n",
       "                       -0.2365,  1.0586],\n",
       "                      [ 0.2112,  0.2087,  0.5212,  0.5857,  0.2838,  0.4703,  0.2103,  0.2953,\n",
       "                        0.3708,  0.1838],\n",
       "                      [ 0.3426,  0.3427,  0.4498,  0.8781,  0.3767,  1.0893,  0.3419,  1.4355,\n",
       "                        1.2543,  0.3486],\n",
       "                      [ 0.0835,  0.0781,  0.3865,  0.7583,  0.1155,  0.6990,  0.0820,  0.5194,\n",
       "                        0.6053,  0.0460],\n",
       "                      [ 0.2004,  0.1996,  0.3244,  0.7349,  0.1947,  0.8372,  0.2004,  0.9607,\n",
       "                        0.8966,  0.1830],\n",
       "                      [ 0.1448,  0.1404,  0.4761,  0.6726,  0.2094,  0.5697,  0.1432,  0.3762,\n",
       "                        0.4632,  0.1126],\n",
       "                      [ 0.3233,  0.3231,  0.4257,  0.8452,  0.3513,  1.0462,  0.3222,  1.3766,\n",
       "                        1.2029,  0.3265],\n",
       "                      [ 0.7422,  0.7568,  0.7361,  0.0575,  0.7810, -0.0997,  0.7480, -0.1690,\n",
       "                       -0.1513,  0.7478],\n",
       "                      [ 0.2781,  0.2782,  0.3793,  0.7838,  0.2913,  0.9493,  0.2776,  1.2139,\n",
       "                        1.0750,  0.2741],\n",
       "                      [ 0.1409,  0.1353,  0.4725,  0.6788,  0.2049,  0.5787,  0.1383,  0.3831,\n",
       "                        0.4704,  0.1085],\n",
       "                      [ 0.2128,  0.2121,  0.3293,  0.7378,  0.2084,  0.8507,  0.2127,  0.9981,\n",
       "                        0.9214,  0.1974]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-1.5866, -2.0370, -1.3194,  0.7576, -0.2276, -1.6148, -1.9272,  0.2897,\n",
       "                      -1.9015, -2.0757, -1.6128,  0.5602, -1.5088, -0.7547, -1.5858,  0.3415,\n",
       "                      -1.9271, -0.1663, -1.5815, -0.6764])),\n",
       "             ('fc4.weight',\n",
       "              tensor([[0.3088, 0.0739, 0.3287,  ..., 0.2718, 0.3185, 0.2917],\n",
       "                      [0.3168, 0.2220, 0.3404,  ..., 0.2619, 0.3231, 0.3045],\n",
       "                      [0.3529, 0.4122, 0.2936,  ..., 0.1744, 0.3529, 0.2220],\n",
       "                      ...,\n",
       "                      [0.1333, 0.1325, 0.1420,  ..., 0.1411, 0.1287, 0.1448],\n",
       "                      [0.2103, 0.1983, 0.2181,  ..., 0.2268, 0.2160, 0.2287],\n",
       "                      [0.2063, 0.1907, 0.2071,  ..., 0.2129, 0.2018, 0.2111]])),\n",
       "             ('fc4.bias',\n",
       "              tensor([ 0.2013, -0.2465, -0.2596,  ...,  0.1553,  0.2623,  0.2345]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"These are parameters of our trained model: \")\n",
    "sae.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.9550700187683105\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0 # initial training loss\n",
    "s = 0. # number of users who rated at least one movie\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0) # training_set[id_user] is a single vector and pytorch wont accept this. There need to be a batch of vectors (size[1,1682]) which we get using Variable class\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False # to make sure that we dont compute the gradient descent to the target\n",
    "        output[target==0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print(\"Test loss: \",float(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test loss is almost 1. This indicates that on average our model is going to predict a rating that is different from the original rating by less than 1 star. It means if a user watches a new movie and gives a rating of 4 then then this model would have predicted the between 3 and 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
